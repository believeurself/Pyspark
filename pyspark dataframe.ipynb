{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5468b80c",
   "metadata": {},
   "source": [
    "# Installation and introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ec2073a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (3.1.2)\n",
      "Requirement already satisfied: py4j==0.10.9 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from pyspark) (0.10.9)\n",
      "\u001b[33mWARNING: You are using pip version 21.1.3; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.9/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4986d0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54a991a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experience</th>\n",
       "      <th>test_score</th>\n",
       "      <th>interview_score</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6</td>\n",
       "      <td>45000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>five</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7</td>\n",
       "      <td>60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>two</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10</td>\n",
       "      <td>65000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>seven</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6</td>\n",
       "      <td>70000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>three</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10</td>\n",
       "      <td>62000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ten</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>72000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>eleven</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8</td>\n",
       "      <td>80000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  experience  test_score  interview_score  salary\n",
       "0        NaN         8.0                9   50000\n",
       "1        NaN         8.0                6   45000\n",
       "2       five         6.0                7   60000\n",
       "3        two        10.0               10   65000\n",
       "4      seven         9.0                6   70000\n",
       "5      three         7.0               10   62000\n",
       "6        ten         NaN                7   72000\n",
       "7     eleven         7.0                8   80000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.read_csv('/Users/subhajitsaha/Documents/Data Science Projects/Salary prediction/hiring.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbd26245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first of all we need to create a spark session \n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a893ad37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting findspark\n",
      "  Downloading findspark-1.4.2-py2.py3-none-any.whl (4.2 kB)\n",
      "Installing collected packages: findspark\n",
      "Successfully installed findspark-1.4.2\n",
      "\u001b[33mWARNING: You are using pip version 21.1.3; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.9/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "751beae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/09/10 20:13:07 WARN Utils: Your hostname, Subhajits-MacBook-Air.local resolves to a loopback address: 127.0.0.1, but we couldn't find any external IP address!\n",
      "21/09/10 20:13:07 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "21/09/10 20:13:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "21/09/10 20:13:10 WARN MacAddressUtil: Failed to find a usable hardware address from the network interfaces; using random bytes: d5:aa:cd:65:71:90:9d:fb\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('Practice').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72efc0fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://localhost:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Practice</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x12240bcd0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfc76efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_pyspark = spark.read.csv('/Users/subhajitsaha/Documents/Data Science Projects/Salary prediction/hiring.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b805f25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_c0: string, _c1: string, _c2: string, _c3: string]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a3f760d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+---------------+------+\n",
      "|       _c0|       _c1|            _c2|   _c3|\n",
      "+----------+----------+---------------+------+\n",
      "|experience|test_score|interview_score|salary|\n",
      "|      null|         8|              9| 50000|\n",
      "|      null|         8|              6| 45000|\n",
      "|      five|         6|              7| 60000|\n",
      "|       two|        10|             10| 65000|\n",
      "|     seven|         9|              6| 70000|\n",
      "|     three|         7|             10| 62000|\n",
      "|       ten|      null|              7| 72000|\n",
      "|    eleven|         7|              8| 80000|\n",
      "+----------+----------+---------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e4b1241",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = spark.read.option('header', 'true').csv('/Users/subhajitsaha/Documents/Data Science Projects/Salary prediction/hiring.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "91e9acb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+---------------+------+\n",
      "|experience|test_score|interview_score|salary|\n",
      "+----------+----------+---------------+------+\n",
      "|      null|         8|              9| 50000|\n",
      "|      null|         8|              6| 45000|\n",
      "|      five|         6|              7| 60000|\n",
      "|       two|        10|             10| 65000|\n",
      "|     seven|         9|              6| 70000|\n",
      "|     three|         7|             10| 62000|\n",
      "|       ten|      null|              7| 72000|\n",
      "|    eleven|         7|              8| 80000|\n",
      "+----------+----------+---------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee975496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_pyspark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "84ea3fd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(experience=None, test_score='8', interview_score='9', salary='50000'),\n",
       " Row(experience=None, test_score='8', interview_score='6', salary='45000'),\n",
       " Row(experience='five', test_score='6', interview_score='7', salary='60000'),\n",
       " Row(experience='two', test_score='10', interview_score='10', salary='65000'),\n",
       " Row(experience='seven', test_score='9', interview_score='6', salary='70000')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6289dac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- experience: string (nullable = true)\n",
      " |-- test_score: string (nullable = true)\n",
      " |-- interview_score: string (nullable = true)\n",
      " |-- salary: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.printSchema()    # info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c616b92c",
   "metadata": {},
   "source": [
    "# Pyspark Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f01d2eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "531ab4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Datframe').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "223a0f0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://localhost:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Datframe</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1115a7460>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "dbbb814d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = spark.read.option('header', 'true').csv('/Users/subhajitsaha/Documents/Data Science Projects/Salary prediction/hiring.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "53a75182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+---------------+------+\n",
      "|experience|test_score|interview_score|salary|\n",
      "+----------+----------+---------------+------+\n",
      "|      null|         8|              9| 50000|\n",
      "|      null|         8|              6| 45000|\n",
      "|      five|         6|              7| 60000|\n",
      "|       two|        10|             10| 65000|\n",
      "|     seven|         9|              6| 70000|\n",
      "|     three|         7|             10| 62000|\n",
      "|       ten|      null|              7| 72000|\n",
      "|    eleven|         7|              8| 80000|\n",
      "+----------+----------+---------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ffbb2ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- experience: string (nullable = true)\n",
      " |-- test_score: string (nullable = true)\n",
      " |-- interview_score: string (nullable = true)\n",
      " |-- salary: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.printSchema()    # by default it takes the values as string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7fa76ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = spark.read.option('header', 'true').csv('/Users/subhajitsaha/Documents/Data Science Projects/Salary prediction/hiring.csv',\n",
    "                                                    inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c336ad62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- experience: string (nullable = true)\n",
      " |-- test_score: integer (nullable = true)\n",
      " |-- interview_score: integer (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# datatypes of column\n",
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f7309db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# or\n",
    "df_pyspark = spark.read.csv('/Users/subhajitsaha/Documents/Data Science Projects/Salary prediction/hiring.csv',\n",
    "                           header=True,\n",
    "                           inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1ce53004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- experience: string (nullable = true)\n",
      " |-- test_score: integer (nullable = true)\n",
      " |-- interview_score: integer (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c6bdf46f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['experience', 'test_score', 'interview_score', 'salary']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fe36a92a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+---------------+------+\n",
      "|experience|test_score|interview_score|salary|\n",
      "+----------+----------+---------------+------+\n",
      "|      null|         8|              9| 50000|\n",
      "|      null|         8|              6| 45000|\n",
      "|      five|         6|              7| 60000|\n",
      "|       two|        10|             10| 65000|\n",
      "|     seven|         9|              6| 70000|\n",
      "|     three|         7|             10| 62000|\n",
      "|       ten|      null|              7| 72000|\n",
      "|    eleven|         7|              8| 80000|\n",
      "+----------+----------+---------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "090bbaa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[experience: string]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.select('experience')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "eb4c834c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|experience|\n",
      "+----------+\n",
      "|      null|\n",
      "|      null|\n",
      "|      five|\n",
      "|       two|\n",
      "|     seven|\n",
      "|     three|\n",
      "|       ten|\n",
      "|    eleven|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.select('experience').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9bde9bc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[experience: string, test_score: int]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.select(['experience', 'test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "664b2b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|experience|test_score|\n",
      "+----------+----------+\n",
      "|      null|         8|\n",
      "|      null|         8|\n",
      "|      five|         6|\n",
      "|       two|        10|\n",
      "|     seven|         9|\n",
      "|     three|         7|\n",
      "|       ten|      null|\n",
      "|    eleven|         7|\n",
      "+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.select(['experience', 'test_score']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f9ee387d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('experience', 'string'),\n",
       " ('test_score', 'int'),\n",
       " ('interview_score', 'int'),\n",
       " ('salary', 'int')]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b7fa7353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, experience: string, test_score: string, interview_score: string, salary: string]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b69b8e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+------------------+------------------+------------------+\n",
      "|summary|experience|        test_score|   interview_score|            salary|\n",
      "+-------+----------+------------------+------------------+------------------+\n",
      "|  count|         6|                 7|                 8|                 8|\n",
      "|   mean|      null| 7.857142857142857|             7.875|           63000.0|\n",
      "| stddev|      null|1.3451854182690985|1.6420805617960927|11501.552690211627|\n",
      "|    min|    eleven|                 6|                 6|             45000|\n",
      "|    max|       two|                10|                10|             80000|\n",
      "+-------+----------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6098e7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding columns\n",
    "df_pyspark = df_pyspark.withColumn('salary after promotion', df_pyspark['salary']+10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5862fed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+---------------+------+----------------------+\n",
      "|experience|test_score|interview_score|salary|salary after promotion|\n",
      "+----------+----------+---------------+------+----------------------+\n",
      "|      null|         8|              9| 50000|                 60000|\n",
      "|      null|         8|              6| 45000|                 55000|\n",
      "|      five|         6|              7| 60000|                 70000|\n",
      "|       two|        10|             10| 65000|                 75000|\n",
      "|     seven|         9|              6| 70000|                 80000|\n",
      "|     three|         7|             10| 62000|                 72000|\n",
      "|       ten|      null|              7| 72000|                 82000|\n",
      "|    eleven|         7|              8| 80000|                 90000|\n",
      "+----------+----------+---------------+------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4ceacbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping columns\n",
    "df_pyspark = df_pyspark.drop('salary after promotion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a2e3046b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+---------------+------+\n",
      "|experience|test_score|interview_score|salary|\n",
      "+----------+----------+---------------+------+\n",
      "|      null|         8|              9| 50000|\n",
      "|      null|         8|              6| 45000|\n",
      "|      five|         6|              7| 60000|\n",
      "|       two|        10|             10| 65000|\n",
      "|     seven|         9|              6| 70000|\n",
      "|     three|         7|             10| 62000|\n",
      "|       ten|      null|              7| 72000|\n",
      "|    eleven|         7|              8| 80000|\n",
      "+----------+----------+---------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5c9e84f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename column\n",
    "df_pyspark = df_pyspark.withColumnRenamed('salary', 'new_salary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5712f0b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+---------------+----------+\n",
      "|experience|test_score|interview_score|new_salary|\n",
      "+----------+----------+---------------+----------+\n",
      "|      null|         8|              9|     50000|\n",
      "|      null|         8|              6|     45000|\n",
      "|      five|         6|              7|     60000|\n",
      "|       two|        10|             10|     65000|\n",
      "|     seven|         9|              6|     70000|\n",
      "|     three|         7|             10|     62000|\n",
      "|       ten|      null|              7|     72000|\n",
      "|    eleven|         7|              8|     80000|\n",
      "+----------+----------+---------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "91871089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping rows\n",
    "# df_pyspark = df_pyspark.na.drop(how='all', subset=['test_score'])\n",
    "# how='any' means if any value is null in a row, drop that row, how='any' means if all values are null, then only drop\n",
    "# thres means, if at least that many non-null values are there, then don't drop that row\n",
    "# subset means, drop null values from that specific column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f7fdb033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+---------------+----------+\n",
      "|experience|test_score|interview_score|new_salary|\n",
      "+----------+----------+---------------+----------+\n",
      "|      null|         8|              9|     50000|\n",
      "|      null|         8|              6|     45000|\n",
      "|      five|         6|              7|     60000|\n",
      "|       two|        10|             10|     65000|\n",
      "|     seven|         9|              6|     70000|\n",
      "|     three|         7|             10|     62000|\n",
      "|       ten|      null|              7|     72000|\n",
      "|    eleven|         7|              8|     80000|\n",
      "+----------+----------+---------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f7b6a382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill the null values\n",
    "df_pyspark = df_pyspark.na.fill(value='zero', subset=['experience'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c6439694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+---------------+----------+\n",
      "|experience|test_score|interview_score|new_salary|\n",
      "+----------+----------+---------------+----------+\n",
      "|      zero|         8|              9|     50000|\n",
      "|      zero|         8|              6|     45000|\n",
      "|      five|         6|              7|     60000|\n",
      "|       two|        10|             10|     65000|\n",
      "|     seven|         9|              6|     70000|\n",
      "|     three|         7|             10|     62000|\n",
      "|       ten|      null|              7|     72000|\n",
      "|    eleven|         7|              8|     80000|\n",
      "+----------+----------+---------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7ed3f02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle missing values\n",
    "from pyspark.ml.feature import Imputer\n",
    "imputer = Imputer(inputCols=['test_score'], outputCols=['{}_imputed'.format(c) for c in ['test_score']]).setStrategy('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "50d32afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+---------------+----------+------------------+\n",
      "|experience|test_score|interview_score|new_salary|test_score_imputed|\n",
      "+----------+----------+---------------+----------+------------------+\n",
      "|      zero|         8|              9|     50000|                 8|\n",
      "|      zero|         8|              6|     45000|                 8|\n",
      "|      five|         6|              7|     60000|                 6|\n",
      "|       two|        10|             10|     65000|                10|\n",
      "|     seven|         9|              6|     70000|                 9|\n",
      "|     three|         7|             10|     62000|                 7|\n",
      "|       ten|      null|              7|     72000|                 7|\n",
      "|    eleven|         7|              8|     80000|                 7|\n",
      "+----------+----------+---------------+----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imputer.fit(df_pyspark).transform(df_pyspark).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2a94d7d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+---------------+----------+\n",
      "|experience|test_score|interview_score|new_salary|\n",
      "+----------+----------+---------------+----------+\n",
      "|      zero|         8|              9|     50000|\n",
      "|      zero|         8|              6|     45000|\n",
      "|      five|         6|              7|     60000|\n",
      "|       two|        10|             10|     65000|\n",
      "|     seven|         9|              6|     70000|\n",
      "|     three|         7|             10|     62000|\n",
      "|       ten|      null|              7|     72000|\n",
      "|    eleven|         7|              8|     80000|\n",
      "+----------+----------+---------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad06cda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
